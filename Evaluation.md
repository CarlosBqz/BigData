**1-. comienza una simple sesion en spark**

Import the following library to start a spark session
```scala
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
```
Declare the variable spark for initialize the session

```scala
val spark = SparkSession.builder().getOrCreate()
```
**2-. cargue el archivo Netflix Stock CSV, haga que Spark infiera los tipos de datos.**
```scala
//Load the csv
val ndf = spark.read.option("header", "true").option("inferSchema","true")csv("C:\\Users\\Carlos Bojorquez\\Desktop\\Evaluacion_Unidad 1_Scala\\Netflix_2011_2016.csv")
```
**3-. ¿Cuáles son los nombres de las columnas?**
```scala
//Name of the columns
ndf.columns
res4: Array[String] = Array(Date, Open, High, Low, Close, Volume, Adj Close)
```

**4-. ¿Cómo es el esquema?**
```scala
ndf.printSchema()


root
 |-- Date: string (nullable = true)
 |-- Open: string (nullable = true)
 |-- High: string (nullable = true)
 |-- Low: string (nullable = true)
 |-- Close: string (nullable = true)
 |-- Volume: string (nullable = true)
 |-- Adj Close: string (nullable = true)
```

**5-. Imprime las primeras 5 columnas.**
```scala
scala> ndf.select("Date", "Open", "High", "Low", "Close").show(1)
```


|               Date|      Open|              High|       Low|     Close|
|-------------------|----------|------------------|----------|----------|
|2011-10-24 00:00:00|119.100002|120.28000300000001|115.100004|118.839996|

only showing top 1 row

**6-. Usa describe () para aprender sobre el DataFrame.**
Using the describe function, this function calculate different things 
```scala
scala> ndf.describe().show()
```

| summary | Date       | Open               | High               | Low                | Close              | Volume               | Adj Close          |
|---------|------------|--------------------|--------------------|--------------------|--------------------|----------------------|--------------------|
| count   | 1259       | 1259               | 1259               | 1259               | 1259               | 1259                 | 1259               |
| mean    | null       | 230.39351086656092 | 233.97320872915006 | 226.80127876251044 | 230.522453845909   | 2.5634836060365368E7 | 55.610540036536875 |
| stddev  | null       | 164.37456353264244 | 165.9705082667129  | 162.6506358235739  | 164.40918905512854 | 2.306312683388607E7  | 35.186669331525486 |
| min     | 2011-10-24 | 100.009999         | 100.050003         | 100.010002         | 100.040001         | 100060100            | 10.017142999999999 |
| max     | 2016-10-24 | 99.970001          | 99.93              | 99.860001          | 99.889999          | 9991800              | 99.889999          |


**7-. Crea un nuevo dataframe con una columna nueva llamada “HV Ratio” que es la relación entre el precio de la columna “High” frente a la columna “Volume” de acciones negociadas por un día.**

```scala
//(Hint: Es una operación de columnas).
ndf.select($"High"/$"Volume").show()

val df7 = ndf.withColumn("HV Ratio", col("High")/col("Volume"))

scala> df7.show()
```

|      Date|             Open|              High|       Low|            Close|   Volume|         Adj Close|            HV Ratio|
|----------|-----------------|------------------|----------|-----------------|---------|------------------|--------------------|
|2011-10-24|       119.100002|120.28000300000001|115.100004|       118.839996|120460200|         16.977142|9.985040951285156E-7|
|2011-10-25|        74.899999|         79.390001| 74.249997|        77.370002|315541800|11.052857000000001|2.515989989281927E-7|
|2011-10-26|            78.73|         81.420001| 75.399997|        79.400002|148733900|         11.342857|5.474206014903126E-7|
|2011-10-27|        82.179998| 82.71999699999999| 79.249998|80.86000200000001| 71190000|11.551428999999999|1.161960907430818...|
|2011-10-28|        80.280002|         84.660002| 79.599999|84.14000300000001| 57769600|             12.02|1.465476686700271...|
|2011-10-31|83.63999799999999|         84.090002| 81.450002|        82.080003| 39653600|         11.725715|2.120614572195210...|
|2011-11-01|        80.109998|         80.999998|     78.74|        80.089997| 33016200|         11.441428|2.453341026526372E-6|
|2011-11-02|        80.709998|         84.400002| 80.109998|        83.389999| 41384000|         11.912857|2.039435578967717E-6|
|2011-11-03|        84.130003|         92.600003| 81.800003|        92.290003| 94685500|13.184285999999998| 9.77974483949496E-7|
|2011-11-04|91.46999699999999| 92.89000300000001| 87.749999|        90.019998| 84483700|             12.86|1.099502069629999...|
|2011-11-07|             91.0|         93.839998| 89.979997|        90.830003| 47485200|         12.975715|1.976194645910725...|
|2011-11-08|91.22999899999999|         92.600003| 89.650002|        90.470001| 31906000|         12.924286|2.902275528113834...|
|2011-11-09|        89.000001|         90.440001| 87.999998|        88.049999| 28756000|         12.578571|3.145082800111281E-6|
|2011-11-10|        89.290001| 90.29999699999999| 84.839999|85.11999899999999| 39614400|             12.16|2.279474054889131E-6|
|2011-11-11|        85.899997|         87.949997|      83.7|        87.749999| 38140200|         12.535714|2.305965805108520...|
|2011-11-14|        87.989998|              88.1|     85.45|        85.719999| 21811300|         12.245714|4.039190694731629...|
|2011-11-15|            85.15|         87.050003| 84.499998|        86.279999| 21372400|         12.325714|4.073010190713256...|
|2011-11-16|        86.460003|         86.460003| 80.890002|        81.180002| 34560400|11.597142999999999|2.501707242971725E-6|
|2011-11-17|            80.77|         80.999998| 75.789999|        76.460001| 52823400|         10.922857|1.533411291208063...|
|2011-11-18|             76.7|         78.999999| 76.039998|        78.059998| 34729100|         11.151428|2.274749388841058...|

only showing top 20 rows

**8-. ¿Qué día tuvo el pico mas alto en la columna “Close”?**

```scala
scala> ndf.select("Date", "Close").sort(desc("Close")).show(1)
```

| Date              |     Close|
|-------------------|----------|
|2015-07-13 00:00:00|707.610001|

only showing top 1 row

**9-. Escribe con tus propias palabras en un comentario de tu codigo. ¿Cuál es el significado de la columna Cerrar “Close”?**
```scala
//Indica el precio con el que cerro el año
```

**10 ¿Cuál es el máximo y mínimo de la columna “Volume”?**

```scala
scala> ndf.agg(min("Close"), max("Close")).show()
```
|min(Volume)|max(Volume)|
------------|-----------|
|    3531300|  315541800|

**11.Con Sintaxis Scala/Spark $ conteste los siguiente:**
◦ Hint: Basicamente muy parecido a la session de dates, tendran que crear otro dataframe para contestar algunos de los incisos.

**a. ¿Cuántos días fue la columna “Close” inferior a $ 600?**
```scala
ndf.filter($"Close" < 600).sort(desc("Close")).show()
scala> ndf.filter($"Close" < 600).sort(desc("Close")).show()
```
|               Date|             Open|             High|              Low|            Close|   Volume|        Adj Close|
|-------------------|-----------------|-----------------|-----------------|-----------------|---------|-----------------|
|2015-05-11 00:00:00|576.2700120000001|       593.999977|575.3000030000001|       589.950005| 23882600|        84.278572|
|2015-05-14 00:00:00|       582.999992|       587.470001|       576.310013|       586.850014|  8898400|        83.835716|
|2015-05-12 00:00:00|       586.659996|       586.659996|       580.950012|583.6400070000001| 11907000|        83.377144|
|2015-05-13 00:00:00|       583.830025|       589.380005|       578.840004|580.1099929999999| 11155900|        82.872856|
|2015-05-08 00:00:00|       567.289993|       575.069984|       566.750008|       574.600014| 13828500|        82.085716|
|2015-04-17 00:00:00|       558.450005|       575.000023|       558.000008|       571.550011| 58306500|        81.650002|
|2015-04-20 00:00:00|       572.499992|       576.129982|       562.670021|567.3900219999999| 30766400|        81.055717|
|2015-04-27 00:00:00|        562.04998|       572.499992|561.6100230000001|       566.079979| 15246700|80.86856800000001|
|2015-05-05 00:00:00|568.6699980000001|       577.099991|       565.299988|        565.54998| 27116600|        80.792854|
|2015-05-07 00:00:00|       560.800018|        565.56002|        556.20002|       565.240013| 10220700|        80.748573|
|2015-04-28 00:00:00|564.1299740000001|       568.950005|559.6099780000001|563.0599900000001|  8826300|        80.437141|
|2015-04-29 00:00:00|       560.489998|567.3900219999999|        557.51001|       562.849998|  9534700|        80.407143|
|2015-04-16 00:00:00|            532.0|           568.75|       530.000008|        562.04998|104500900|        80.292854|
|2015-05-06 00:00:00|       567.200005|       568.500008|       556.650017|       560.539986| 11504500|        80.077141|
|2015-04-21 00:00:00|       568.639984|       570.389984|       558.600021|560.4400099999999| 15925700|        80.062859|
|2015-04-23 00:00:00|       557.590012|       562.400002|        552.68998|559.0600049999999| 12687500|79.86571500000001|
|2015-04-24 00:00:00|       561.210014|       565.659996|       556.549988|       558.400017| 11045300|        79.771431|
|2015-04-22 00:00:00|        561.47998|       564.990021|        556.81002|           557.68| 12089700|        79.668571|
|2015-05-01 00:00:00|        558.98999|559.7699809999999|        552.26001|       557.029999|  8906100|        79.575714|
|2015-04-30 00:00:00|       561.660011|       565.850014|553.8699799999999|            556.5| 10565100|             79.5|

only showing top 20 rows

```Scala
val a11 =  ndf.filter($"Close" < 600)

a11.sort(desc("Close"))

a11.count
Long = 1218
```
**b. ¿Qué porcentaje del tiempo fue la columna “High” mayor que $ 500?**
```scala
val b11 =  ndf.filter($"High" > 500)
b11.sort(asc("High")).show()
var b11percent: Double = (b11.count.toDouble/ndf.count.toDouble)*100

b11percent: Double = 4.924543288324067	
```
**c. ¿Cuál es la correlación de Pearson entre columna “High” y la columna “Volumen”?**
```scala
scala> ndf.select(corr($"High",$"Volume")).show()
```
|  corr(High, Volume)|
|--------------------|
|-0.20960233287942157|

**d. ¿Cuál es el máximo de la columna “High” por año?**
```scala
ndf.groupBy(year($"Date")).agg(max($"High")).sort(year($"Date")).show()
```
|year(Date)|         max(High)|
|--------------------|--------------------|
|      2011|120.28000300000001|
|      2012|        133.429996|
|      2013|        389.159988|
|      2014|        489.290024|
|      2015|        716.159996|
|      2016|129.28999299999998|

**e. ¿Cuál es el promedio de columna “Close” para cada mes del calendario?**

```scala
ndf.groupBy(month($"Date")).agg(mean($"Close")).sort(month($"Date")).show()
```

|month(Date)|        avg(Close)|
|--------------------|--------------------|
|          1|212.22613874257422|
|          2| 254.1954634020619|
|          3| 249.5825228971963|
|          4|246.97514271428562|
|          5|264.37037614150944|
|          6| 295.1597153490566|
|          7|243.64747528037387|
|          8|195.25599892727263|
|          9|206.09598121568627|
|         10|205.93297300900903|
|         11| 194.3172275445545|
|         12| 199.3700942358491|
